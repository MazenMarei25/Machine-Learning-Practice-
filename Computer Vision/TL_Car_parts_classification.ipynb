{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "TL_Car_parts_classification",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7694272,
          "sourceType": "datasetVersion",
          "datasetId": 4480592,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MazenMarei25/Machine-Learning-Practice-/blob/main/Computer%20Vision/TL_Car_parts_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "gpiosenka_car_parts_40_classes_path = kagglehub.dataset_download('gpiosenka/car-parts-40-classes')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "nhGJzYu5m3HB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dataset"
      ],
      "metadata": {
        "id": "YVxw8CWBnenZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"gpiosenka/car-parts-40-classes\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "mXGpYo6PE5N9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:45:40.473718Z",
          "iopub.execute_input": "2026-02-05T11:45:40.473957Z",
          "iopub.status.idle": "2026-02-05T11:45:41.679084Z",
          "shell.execute_reply.started": "2026-02-05T11:45:40.473932Z",
          "shell.execute_reply": "2026-02-05T11:45:41.678292Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/kaggle/input/car-parts-40-classes/car parts/train\"\n",
        "test_dir = \"/kaggle/input/car-parts-40-classes/car parts/test\"\n",
        "valid_dir = \"/kaggle/input/car-parts-40-classes/car parts/valid\""
      ],
      "metadata": {
        "id": "0nmjEic8TuYE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:46:32.79143Z",
          "iopub.execute_input": "2026-02-05T11:46:32.791913Z",
          "iopub.status.idle": "2026-02-05T11:46:32.795543Z",
          "shell.execute_reply.started": "2026-02-05T11:46:32.791886Z",
          "shell.execute_reply": "2026-02-05T11:46:32.794802Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint,EarlyStopping\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "mfQPVH5RFLUf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:46:34.72122Z",
          "iopub.execute_input": "2026-02-05T11:46:34.72182Z",
          "iopub.status.idle": "2026-02-05T11:46:56.145486Z",
          "shell.execute_reply.started": "2026-02-05T11:46:34.721789Z",
          "shell.execute_reply": "2026-02-05T11:46:56.144939Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Naming the model with a timestamp to save it for later\n",
        "ckpt_dir = 'kaggle/working/CV/checkpoints'\n",
        "\n",
        "NAME = \"car-parts-cnn-classifier-{}\".format(int(time.time()))\n",
        "\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "ckpt_path = os.path.join(\n",
        "    ckpt_dir,\n",
        "    f\"{NAME}_epoch-{{epoch:02d}}.keras\"\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=ckpt_path,\n",
        "    save_weights_only=False,   # saves full model\n",
        "    save_freq='epoch'          # saves after every epoch\n",
        ")\n"
      ],
      "metadata": {
        "id": "3eVVOLYQnj96",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:06.175437Z",
          "iopub.execute_input": "2026-02-05T11:48:06.176037Z",
          "iopub.status.idle": "2026-02-05T11:48:06.180538Z",
          "shell.execute_reply.started": "2026-02-05T11:48:06.17601Z",
          "shell.execute_reply": "2026-02-05T11:48:06.179682Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the dataset"
      ],
      "metadata": {
        "id": "JeLH5i5EISHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create from the train,test,val folders the datasets in the format expected by keras\n",
        "# tf.keras.preprocessing.image_dataset_from_directory() automatically creates an interable of batches of image label pairs\n",
        "\n",
        "IMAGE_SIZE = (224,224)\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(train_dir,label_mode=\"int\",batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,shuffle=\"True\",seed=42,color_mode=\"rgb\")\n",
        "\n",
        "test_ds=tf.keras.preprocessing.image_dataset_from_directory(test_dir,label_mode=\"int\",batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,shuffle=\"True\",seed=42,color_mode=\"rgb\")\n",
        "\n",
        "valid_ds=tf.keras.preprocessing.image_dataset_from_directory(valid_dir,label_mode=\"int\",batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,shuffle=\"True\",seed=42,color_mode=\"rgb\")"
      ],
      "metadata": {
        "id": "GKiwsIVVK4PX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:09.274663Z",
          "iopub.execute_input": "2026-02-05T11:48:09.27497Z",
          "iopub.status.idle": "2026-02-05T11:48:12.141615Z",
          "shell.execute_reply.started": "2026-02-05T11:48:09.274929Z",
          "shell.execute_reply": "2026-02-05T11:48:12.141071Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# take 1 batch of the image and show its size\n",
        "for images, labels in train_ds.take(1):\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # (32, 256, 256, 3) | 32 batches each image is 160x160 and has 3 channels RGB"
      ],
      "metadata": {
        "id": "g1vzSVv6VGDt",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:20.169263Z",
          "iopub.execute_input": "2026-02-05T11:48:20.169773Z",
          "iopub.status.idle": "2026-02-05T11:48:20.300261Z",
          "shell.execute_reply.started": "2026-02-05T11:48:20.169746Z",
          "shell.execute_reply": "2026-02-05T11:48:20.29951Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print the class names just to make sure\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "print(len(class_names)) # 40 classes"
      ],
      "metadata": {
        "id": "CIcyI6DkWCDu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:24.492701Z",
          "iopub.execute_input": "2026-02-05T11:48:24.493037Z",
          "iopub.status.idle": "2026-02-05T11:48:24.497109Z",
          "shell.execute_reply.started": "2026-02-05T11:48:24.49301Z",
          "shell.execute_reply": "2026-02-05T11:48:24.49643Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the train set\n",
        "# load a batch from train_ds\n",
        "# load 9 images and show them sequentially in a 3x3 grid\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(7):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KQzN7wOWGkx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:29.3696Z",
          "iopub.execute_input": "2026-02-05T11:48:29.370175Z",
          "iopub.status.idle": "2026-02-05T11:48:29.91751Z",
          "shell.execute_reply.started": "2026-02-05T11:48:29.370148Z",
          "shell.execute_reply": "2026-02-05T11:48:29.916758Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the images\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "\n",
        "# We normalize the images in our datasets to lie between [0,1] by using a normalization layer\n",
        "# This layer divides the inputs by 255\n",
        "# Note that, sometimes the model (if using a pretrained model) expects [-1,1] so we need to adjust our rescaling factor\n",
        "# Lambda is a shortened function notation that does the equivalent of :\n",
        "#\n",
        "#def normalize_batch(x, y):\n",
        "#    x_norm = normalization_layer(x)\n",
        "#    return x_norm, y\n",
        "# map() applies lambda to every batch in the dataset\n",
        "\n",
        "normalization_layer = Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds   = valid_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "71BqWW2yjbeD",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:38.81807Z",
          "iopub.execute_input": "2026-02-05T11:48:38.818371Z",
          "iopub.status.idle": "2026-02-05T11:48:38.874991Z",
          "shell.execute_reply.started": "2026-02-05T11:48:38.818345Z",
          "shell.execute_reply": "2026-02-05T11:48:38.87445Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Model"
      ],
      "metadata": {
        "id": "uwyTyuWqFjqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.applications import EfficientNetB0\n"
      ],
      "metadata": {
        "id": "fSP2ai9OFpCU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:48:42.297937Z",
          "iopub.execute_input": "2026-02-05T11:48:42.29825Z",
          "iopub.status.idle": "2026-02-05T11:48:42.305285Z",
          "shell.execute_reply.started": "2026-02-05T11:48:42.298223Z",
          "shell.execute_reply": "2026-02-05T11:48:42.304774Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load EfficientNetB0 without top\n",
        "base_model = EfficientNetB0(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Freeze the base model for transfer learning\n",
        "base_model.trainable = False\n",
        "\n",
        "# Functional API\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs)                 # <-- pass inputs through base_model\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(40, activation=\"softmax\")(x)\n",
        "\n",
        "# Create model\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile\n",
        "opt = Adam(learning_rate=0.0005)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ujL2JuhqfoCN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:50:37.357067Z",
          "iopub.execute_input": "2026-02-05T11:50:37.35778Z",
          "iopub.status.idle": "2026-02-05T11:50:38.327951Z",
          "shell.execute_reply.started": "2026-02-05T11:50:37.357721Z",
          "shell.execute_reply": "2026-02-05T11:50:38.327405Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "ClSyxTIKfpYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping\n",
        "stopping=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-4,\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:50:49.896124Z",
          "iopub.execute_input": "2026-02-05T11:50:49.896409Z",
          "iopub.status.idle": "2026-02-05T11:50:49.90053Z",
          "shell.execute_reply.started": "2026-02-05T11:50:49.896383Z",
          "shell.execute_reply": "2026-02-05T11:50:49.899992Z"
        },
        "id": "qvNChgybm3HT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Choice of epochs is arbitrary\n",
        "epochs=100\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds, # Validation set : used to monitor model performance during training while test is used to evaluate the model after it has been trained\n",
        "  epochs=epochs,\n",
        "  callbacks=[checkpoint,stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "8FsEfOdzforX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T11:50:53.095216Z",
          "iopub.execute_input": "2026-02-05T11:50:53.095817Z",
          "iopub.status.idle": "2026-02-05T12:09:20.182262Z",
          "shell.execute_reply.started": "2026-02-05T11:50:53.095788Z",
          "shell.execute_reply": "2026-02-05T12:09:20.181487Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing our model"
      ],
      "metadata": {
        "id": "RVU1QVodtGxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.evaluate(test_ds)\n",
        "print(\"Test Loss:\", metrics[0])\n",
        "print(\"Test Accuracy:\", metrics[1])"
      ],
      "metadata": {
        "id": "icqXjcxFtGY5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T12:09:28.172707Z",
          "iopub.execute_input": "2026-02-05T12:09:28.173328Z",
          "iopub.status.idle": "2026-02-05T12:09:28.66562Z",
          "shell.execute_reply.started": "2026-02-05T12:09:28.173299Z",
          "shell.execute_reply": "2026-02-05T12:09:28.66506Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(test_ds))  # batch size 32\n",
        "\n",
        "# Predict **only for this batch**\n",
        "pred_probs = model.predict(images)\n",
        "pred_classes = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Number of images to display\n",
        "num_images = min(len(images), 7)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(num_images):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    img = images[i]\n",
        "\n",
        "    # Convert TF tensor to NumPy if needed\n",
        "    if isinstance(img, tf.Tensor):\n",
        "        img = img.numpy()\n",
        "\n",
        "    # Scale to 0-255 if floats\n",
        "    if img.max() <= 1.0:\n",
        "        img = (img * 255).astype(\"uint8\")\n",
        "    else:\n",
        "        img = img.astype(\"uint8\")\n",
        "\n",
        "    # Get true and predicted labels\n",
        "    true_label = class_names[labels[i] if isinstance(labels, np.ndarray) else labels[i].numpy()]\n",
        "    pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "    # Color title green if correct, red if wrong\n",
        "    color = 'green' if true_label == pred_label else 'red'\n",
        "    plt.title(f\"T: {true_label}\\nP: {pred_label}\", color=color)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-05T12:09:33.183468Z",
          "iopub.execute_input": "2026-02-05T12:09:33.183777Z",
          "iopub.status.idle": "2026-02-05T12:09:39.83955Z",
          "shell.execute_reply.started": "2026-02-05T12:09:33.183751Z",
          "shell.execute_reply": "2026-02-05T12:09:39.838752Z"
        },
        "id": "ULiJjRg3m3HV"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}