{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10387261,
          "sourceType": "datasetVersion",
          "datasetId": 6435081,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "data_test",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MazenMarei25/Machine-Learning-Practice-/blob/main/Regression/data_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "govindaramsriram_energy_consumption_dataset_linear_regression_path = kagglehub.dataset_download('govindaramsriram/energy-consumption-dataset-linear-regression')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "7OwY0USNKuEl"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Importing dataset"
      ],
      "metadata": {
        "id": "wkaHwwiBKuEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"govindaramsriram/energy-consumption-dataset-linear-regression\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T09:46:16.694768Z",
          "iopub.execute_input": "2026-02-02T09:46:16.695057Z",
          "iopub.status.idle": "2026-02-02T09:46:22.236429Z",
          "shell.execute_reply.started": "2026-02-02T09:46:16.695029Z",
          "shell.execute_reply": "2026-02-02T09:46:22.235481Z"
        },
        "id": "MQrhWCELKuEo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = data = pd.read_csv(\"/kaggle/input/energy-consumption-dataset-linear-regression/train_energy_data.csv\")\n",
        "x = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:54:21.460165Z",
          "iopub.execute_input": "2026-02-02T10:54:21.460572Z",
          "iopub.status.idle": "2026-02-02T10:54:21.487719Z",
          "shell.execute_reply.started": "2026-02-02T10:54:21.460543Z",
          "shell.execute_reply": "2026-02-02T10:54:21.486528Z"
        },
        "id": "TeI-l3J5KuEp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])\n",
        "print(y[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:54:22.889587Z",
          "iopub.execute_input": "2026-02-02T10:54:22.889898Z",
          "iopub.status.idle": "2026-02-02T10:54:22.897009Z",
          "shell.execute_reply.started": "2026-02-02T10:54:22.889873Z",
          "shell.execute_reply": "2026-02-02T10:54:22.895545Z"
        },
        "id": "iY48vLE3KuEq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Data preprocessing"
      ],
      "metadata": {
        "id": "Qutx0twbKuEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "\n",
        "# standarizing the numeric values\n",
        "scaler = StandardScaler()\n",
        "x[:, 1:-1] = scaler.fit_transform(x[:, 1:-1])\n",
        "\n",
        "x_norm = x[:,1:-1].copy()\n",
        "\n",
        "le0 = LabelEncoder()\n",
        "le1 = LabelEncoder()\n",
        "# One hot encoding the categorical data\n",
        "x[:, 0]  = le0.fit_transform(x[:, 0])\n",
        "x[:, -1] = le1.fit_transform(x[:, -1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:56:12.629831Z",
          "iopub.execute_input": "2026-02-02T10:56:12.630171Z",
          "iopub.status.idle": "2026-02-02T10:56:12.640881Z",
          "shell.execute_reply.started": "2026-02-02T10:56:12.630143Z",
          "shell.execute_reply": "2026-02-02T10:56:12.63939Z"
        },
        "id": "Tb-Wt9ZmKuEs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])\n",
        "print(y[0])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:56:14.946665Z",
          "iopub.execute_input": "2026-02-02T10:56:14.947029Z",
          "iopub.status.idle": "2026-02-02T10:56:14.952972Z",
          "shell.execute_reply.started": "2026-02-02T10:56:14.946999Z",
          "shell.execute_reply": "2026-02-02T10:56:14.951956Z"
        },
        "id": "KrR-TjOUKuEt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_norm[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:56:16.903867Z",
          "iopub.execute_input": "2026-02-02T10:56:16.904202Z",
          "iopub.status.idle": "2026-02-02T10:56:16.909613Z",
          "shell.execute_reply.started": "2026-02-02T10:56:16.904167Z",
          "shell.execute_reply": "2026-02-02T10:56:16.908561Z"
        },
        "id": "jONH2PWpKuEu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Visualizing data spread"
      ],
      "metadata": {
        "id": "lpfcIIKNKuEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# features you want to plot (skip index 0 and 5 because they are categorical)\n",
        "feature_indices = [1, 2, 3, 4]\n",
        "\n",
        "for ax, i in zip(axes, feature_indices):\n",
        "    ax.scatter(x[:, i], y)\n",
        "    ax.set_xlabel(f\"Feature {i}\")\n",
        "    ax.set_ylabel(\"Target (y)\")\n",
        "    ax.set_title(f\"Feature {i} vs y\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T10:54:28.267417Z",
          "iopub.execute_input": "2026-02-02T10:54:28.267869Z",
          "iopub.status.idle": "2026-02-02T10:54:29.146044Z",
          "shell.execute_reply.started": "2026-02-02T10:54:28.267828Z",
          "shell.execute_reply": "2026-02-02T10:54:29.144943Z"
        },
        "id": "_PdyM350KuEw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_norm[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T11:04:48.404617Z",
          "iopub.execute_input": "2026-02-02T11:04:48.404961Z",
          "iopub.status.idle": "2026-02-02T11:04:48.410958Z",
          "shell.execute_reply.started": "2026-02-02T11:04:48.404931Z",
          "shell.execute_reply": "2026-02-02T11:04:48.409759Z"
        },
        "id": "K2eVTeBpKuEx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Correclation Matrix\n",
        "Though individually each feature does not show high correlation but the problem can appear as a linear combination. This is why PCA is done"
      ],
      "metadata": {
        "id": "3AUTV6HeKuEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x_1 = x_norm[:, 0].astype(float)\n",
        "y_f = y.flatten().astype(float)\n",
        "\n",
        "# compute correlation\n",
        "x1_y = np.corrcoef(x_1, y_f)\n",
        "\n",
        "print(\"Correlation matrix:\\n\", x1_y)\n",
        "print(\"Single correlation value x1_y:\", x1_y[0, 1])\n",
        "\n",
        "x_2 = x_norm[:, 1].astype(float)\n",
        "# compute correlation\n",
        "x2_y = np.corrcoef(x_2, y_f)\n",
        "\n",
        "print(\"Correlation matrix:\\n\", x2_y)\n",
        "print(\"Single correlation value x1_y:\", x2_y[0, 1])\n",
        "\n",
        "x_3 = x_norm[:, 2].astype(float)\n",
        "# compute correlation\n",
        "x3_y = np.corrcoef(x_3, y_f)\n",
        "\n",
        "print(\"Correlation matrix:\\n\", x3_y)\n",
        "print(\"Single correlation value x1_y:\", x3_y[0, 1])\n",
        "\n",
        "x_4 = x_norm[:, 3].astype(float)\n",
        "# compute correlation\n",
        "x4_y = np.corrcoef(x_4, y_f)\n",
        "\n",
        "print(\"Correlation matrix:\\n\", x4_y)\n",
        "print(\"Single correlation value x1_y:\", x4_y[0, 1])\n",
        "\n",
        "\n",
        "#print(x_norm[0])\n",
        "#print(y[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T11:05:16.614045Z",
          "iopub.execute_input": "2026-02-02T11:05:16.614506Z",
          "iopub.status.idle": "2026-02-02T11:05:16.629271Z",
          "shell.execute_reply.started": "2026-02-02T11:05:16.614464Z",
          "shell.execute_reply": "2026-02-02T11:05:16.627978Z"
        },
        "id": "Cwi_rIezKuEx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "\n",
        "x_pca = pca.fit_transform(x)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T11:22:59.353759Z",
          "iopub.execute_input": "2026-02-02T11:22:59.354179Z",
          "iopub.status.idle": "2026-02-02T11:23:00.004305Z",
          "shell.execute_reply.started": "2026-02-02T11:22:59.354148Z",
          "shell.execute_reply": "2026-02-02T11:23:00.002737Z"
        },
        "id": "vggwsebCKuEx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained variance ratio per component:\", explained_variance)\n",
        "print(\"Cumulative variance:\", np.cumsum(explained_variance))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T11:23:04.386292Z",
          "iopub.execute_input": "2026-02-02T11:23:04.387193Z",
          "iopub.status.idle": "2026-02-02T11:23:04.3929Z",
          "shell.execute_reply.started": "2026-02-02T11:23:04.387157Z",
          "shell.execute_reply": "2026-02-02T11:23:04.391738Z"
        },
        "id": "jgjwT17gKuEx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(np.cumsum(explained_variance), marker='o')\n",
        "plt.xlabel(\"Number of principal components\")\n",
        "plt.ylabel(\"Cumulative explained variance\")\n",
        "plt.title(\"PCA - variance captured\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# lotting the cumulative explained variance shows that all 6 features together capture 100% of the data’s variance. This indicates that the dataset is synthetic and perfectly linear, with little to no noise."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-02T11:23:33.654865Z",
          "iopub.execute_input": "2026-02-02T11:23:33.65521Z",
          "iopub.status.idle": "2026-02-02T11:23:33.826996Z",
          "shell.execute_reply.started": "2026-02-02T11:23:33.655181Z",
          "shell.execute_reply": "2026-02-02T11:23:33.825956Z"
        },
        "id": "k4TTfuW0KuEy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- Final Conclusion\n",
        "\n",
        " The cumulative explained variance shows that all 6 features together capture 100% of the data’s variance. This indicates that the dataset is synthetic and perfectly linear, with little to no noise.\n",
        "\n",
        " Cumulative variance: [0.21907994 0.42888144 0.62429211 0.81232389 0.94941944 1.        ]\n",
        "\n",
        " The 1 at index 5 indicates that all 6 features can reconstruct the model perfectly.\n",
        " In a real life dataset we will have noise and maybe some nonlinearities wich would not cause a perfect score of 1 to appear"
      ],
      "metadata": {
        "id": "jjZPFFfyKuEy"
      }
    }
  ]
}